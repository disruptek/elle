=================================================================================
ELLE PARSER IMPLEMENTATION - FILE PATHS & CODE SNIPPETS SUMMARY
=================================================================================

KEY FILES (All in /home/adavidoff/git/elle/src/):
================================================================================

1. /home/adavidoff/git/elle/src/reader.rs [647 lines]
   - Main parser/lexer implementation
   - Lexer struct: lines 45-355
   - Reader struct: lines 357-591
   - read_str entry point: lines 594-616
   - Token enum: lines 24-43

2. /home/adavidoff/git/elle/src/value.rs [442 lines]
   - Value enum definition: lines 142-163
   - SymbolId struct: lines 6-11
   - Cons cell structure: lines 48-58
   - Helper functions (cons, list): lines 408-420
   - list_to_vec traversal: lines 294-307

3. /home/adavidoff/git/elle/src/symbol.rs [139 lines]
   - SymbolTable struct: lines 30-38
   - intern() function: lines 51-61
   - gensym_id() for macro hygiene: lines 10-12

4. /home/adavidoff/git/elle/src/primitives/list.rs [115+ lines]
   - List manipulation primitives
   - prim_cons, prim_first, prim_rest
   - prim_length, prim_nth (performance-critical)
   - prim_append, prim_reverse

5. /home/adavidoff/git/elle/src/compiler/ast.rs [219 lines]
   - AST representation (Expr enum)
   - Pattern matching structures
   - Expr variants for compilation

6. /home/adavidoff/git/elle/src/compiler/converters.rs [100+ lines]
   - value_to_expr(): Convert Value to AST
   - adjust_var_indices(): Variable resolution
   - Macro expansion hooks

7. /home/adavidoff/git/elle/benches/benchmarks.rs [343 lines]
   - Performance benchmarks
   - Parsing, symbol interning, compilation tests
   - Memory operation benchmarks
   - Scalability tests

================================================================================
CORE PARSING FLOW
================================================================================

1. read_str(input: &str, symbols: &mut SymbolTable)
   Location: reader.rs:594-616
   
   Steps:
   a. Strip shebang if present
   b. Create Lexer from input string
   c. Collect all tokens via Lexer::next_token()
   d. Create Reader with token Vec
   e. Call Reader::read() to parse first value

2. Lexer::next_token_with_loc()
   Location: reader.rs:189-349
   
   Returns: Option<TokenWithLoc> with SourceLoc (line, col)
   
   Handles:
   - Parentheses: ( ) [ ] { }
   - Quoting: ' ` , ,@
   - Keywords: :name
   - Numbers: integers and floats
   - Strings: "..." with escape sequences
   - Symbols: alphanumeric identifiers
   - Comments: ; to end of line

3. Reader::read_one(token)
   Location: reader.rs:385-505
   
   Dispatches on token type:
   - LeftParen → read_list()
   - LeftBracket → read_vector()
   - LeftBrace → read_struct()
   - ListSugar (@) → sugar expansion
   - Quote/Quasiquote/Unquote → wrapping
   - Numbers/Strings/Symbols → direct conversion

4. read_list() / read_vector() / read_struct()
   Location: reader.rs:514-591
   
   Common pattern:
   - Collect elements in Vec
   - Reverse and fold with cons/Vector constructor
   - Elements recursively parsed via read()

================================================================================
TOKENIZATION INTERNALS
================================================================================

Key Methods:

1. Lexer::skip_whitespace()
   - Lines: 88-103
   - Skips whitespace and ; comments
   - Handles EOF

2. Lexer::read_string()
   - Lines: 105-134
   - Supports: \n, \t, \r, \\, \"
   - String accumulation in Vec

3. Lexer::read_number()
   - Lines: 136-162
   - Distinguishes: i64 vs f64
   - Issue: Extra lookahead for sign handling

4. Lexer::read_symbol()
   - Lines: 164-174
   - Stops at whitespace or "()[]{}'`,:@"
   - PAIN POINT: contains(c) linear search

5. Lexer::parse_qualified_symbol()
   - Lines: 176-187
   - Handles: module:symbol syntax
   - Converts to (qualified-ref module name)

================================================================================
VALUE CONSTRUCTION
================================================================================

Cons Cell (Lines 48-58 in value.rs):

pub struct Cons {
    pub first: Value,    // CAR
    pub rest: Value,     // CDR
}

pub fn cons(first: Value, rest: Value) -> Value {
    Value::Cons(Rc::new(Cons::new(first, rest)))
}

List Construction (Lines 409-414 in value.rs):

pub fn list(values: Vec<Value>) -> Value {
    values
        .into_iter()
        .rev()
        .fold(Value::Nil, |acc, v| Value::Cons(Rc::new(Cons::new(v, acc))))
}

Memory: Each Cons wrapped in Rc<> for reference counting

PAIN POINTS:
- Intermediate Vec allocation
- O(n) allocations for cons cells
- O(n) cloning on access (list_to_vec)
- No cached length

================================================================================
SYMBOL INTERNING
================================================================================

SymbolTable Structure (Lines 30-38 in symbol.rs):

pub struct SymbolTable {
    map: FxHashMap<String, SymbolId>,       // Name → ID (primary)
    names: Vec<String>,                      // ID → Name (reverse)
    macros: FxHashMap<SymbolId, Rc<MacroDef>>,
    modules: FxHashMap<SymbolId, Rc<ModuleDef>>,
    current_module: Option<SymbolId>,
}

Intern Process (Lines 51-61):

pub fn intern(&mut self, name: &str) -> SymbolId {
    if let Some(&id) = self.map.get(name) {
        return id;  // Cache hit: O(1)
    }
    
    // New symbol
    let id = SymbolId(self.names.len() as u32);
    self.names.push(name.to_string());
    self.map.insert(name.to_string(), id);
    id
}

Performance:
- First intern: O(1) hash + insert
- Repeated intern: O(1) hash lookup
- Symbol comparison: O(1) ID comparison
- Issue: String duplication (map key + vec value)

================================================================================
SYMBOL ID DEFINITION
================================================================================

Location: value.rs, lines 6-11

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct SymbolId(pub u32);

Properties:
- 32-bit unsigned integer (u32)
- Implements Copy (passed by value)
- O(1) comparison
- Hashable (used in HashMap/BTreeMap keys)
- Supports ordering (used in BTreeMap)

Limit: 2^32 unique symbols (~4 billion)

================================================================================
PERFORMANCE CHARACTERISTICS
================================================================================

PARSING PHASE:
- Input: String → Vec<char> conversion: O(n) time, O(n) space
- Lexing: O(n) tokens, O(1) per token
- Reading: O(n) elements, O(1) per element
- Overall: O(n) time, O(n) space

LIST OPERATIONS:
- Construction: O(n) time, O(n) allocations
- Traversal (list_to_vec): O(n) time, O(n) space, 2n clones
- Length check: O(n) traversal
- Nth access: O(n) traversal
- First access: O(1)

SYMBOL OPERATIONS:
- Intern: O(1) average, O(h) worst (hash collision)
- Lookup: O(1) average
- Comparison: O(1)

TOP BOTTLENECKS:
1. String→Vec<char> upfront conversion
2. Delimiter set checking with contains()
3. List traversal for every operation
4. Reference counting overhead
5. Symbol name duplication
6. No length caching on lists

================================================================================
CRITICAL CODE SNIPPETS
================================================================================

Pain Point #1: Input Conversion (reader.rs:55)

pub fn new(input: &str) -> Self {
    Lexer {
        input: input.chars().collect(),  // ← O(n) allocation!
        pos: 0,
        line: 1,
        col: 1,
    }
}

Pain Point #2: Delimiter Check (reader.rs:167)

if c.is_whitespace() || "()[]{}'`,:@".contains(c) {  // ← Linear search!
    break;
}

Pain Point #3: List Traversal (value.rs:294-307)

pub fn list_to_vec(&self) -> Result<Vec<Value>, String> {
    let mut result = Vec::new();
    let mut current = self.clone();  // ← Cloning entire value!
    loop {
        match current {
            Value::Nil => return Ok(result),
            Value::Cons(cons) => {
                result.push(cons.first.clone());  // ← Cloning element!
                current = cons.rest.clone();       // ← Cloning rest!
            }
            _ => return Err("Not a proper list"),
        }
    }
}

Pain Point #4: Repeated Traversals (primitives/list.rs:36-41)

pub fn prim_length(args: &[Value]) -> Result<Value, String> {
    let vec = args[0].list_to_vec()?;  // ← O(n) traversal to get length!
    Ok(Value::Int(vec.len() as i64))
}

pub fn prim_nth(args: &[Value]) -> Result<Value, String> {
    let index = args[0].as_int()? as usize;
    let vec = args[1].list_to_vec()?;  // ← O(n) traversal for one element!
    vec.get(index).cloned()
}

================================================================================
DATA STRUCTURE SUMMARY
================================================================================

Component             | Type                    | Size  | Performance
---------------------|-------------------------|-------|----------------
Lexer input           | Vec<char>               | O(n)  | O(1) access, O(n) init
Token stream          | Vec<Token>              | O(n)  | O(1) random access
Reader position       | usize                   | 8B    | O(1) position
Symbol name→ID        | FxHashMap<String, ID>   | O(n)  | O(1) lookup
Symbol ID→name        | Vec<String>             | O(n)  | O(1) lookup
Macro definitions     | FxHashMap<ID, MacroDef>| O(m)  | O(1) lookup
Module definitions    | FxHashMap<ID, ModuleDef>| O(m) | O(1) lookup
Cons cell             | Rc<Cons>                | 8B    | O(1) clone, O(n) traverse
Vector                | Rc<Vec<Value>>          | 8B    | O(1) access, O(n) clone
Table (mutable)       | Rc<RefCell<BTreeMap>>   | 8B    | O(log n) ops
Struct (immutable)    | Rc<BTreeMap>            | 8B    | O(log n) ops

Where: n = input/list length, m = macro/module count

================================================================================
BENCHMARK TESTS
================================================================================

Location: /home/adavidoff/git/elle/benches/benchmarks.rs (343 lines)

Test Groups:

1. bench_parsing: Lexing/Reading speed
   - simple_number, list_literal, nested_expr
   - deep_nesting, large_list_100

2. bench_symbol_interning: Symbol caching
   - first_intern, repeat_intern, many_unique

3. bench_compilation: AST generation speed
   - simple_arithmetic, conditional, nested_arithmetic

4. bench_vm_execution: Runtime performance
   - int_add, mixed_arithmetic, comparison, cons, first

5. bench_conditionals: If/cond performance

6. bench_end_to_end: Full pipeline

7. bench_scalability: Scaling with input size
   - list_construction, addition_chain (sizes: 10, 50, 100, 500)

8. bench_memory_operations: Memory overhead
   - value_clone, list_to_vec

Key Insight: Memory operations are tracked as a pain point!

================================================================================
